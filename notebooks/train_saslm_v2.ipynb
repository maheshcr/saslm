{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SASLM v2 Training Notebook\n",
    "\n",
    "Train the Sri Aurobindo Small Language Model with:\n",
    "- Weighted sampling (mature works prioritized)\n",
    "- Checkpointing to Google Drive (survives disconnects)\n",
    "- Grokking detection\n",
    "- Comprehensive logging\n",
    "\n",
    "## Experiments\n",
    "- **EXP-A1**: From scratch, prose only\n",
    "- **EXP-B1**: Fine-tune GPT-2, prose only\n",
    "- **EXP-A2**: From scratch, prose + poetry\n",
    "- **EXP-B2**: Fine-tune GPT-2, prose + poetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths - CORPUS IS ON GOOGLE DRIVE\n",
    "DRIVE_BASE = '/content/drive/MyDrive/saslm'\n",
    "CORPUS_PATH = f'{DRIVE_BASE}/clean_prose'  # Your uploaded corpus\n",
    "EXPERIMENTS_PATH = f'{DRIVE_BASE}/experiments'  # Checkpoints will be saved here\n",
    "TOKENIZER_PATH = f'{DRIVE_BASE}/tokenizers/tokenizer_16k'  # Tokenizer on Drive too\n",
    "\n",
    "print(f\"Corpus path: {CORPUS_PATH}\")\n",
    "print(f\"Experiments path: {EXPERIMENTS_PATH}\")\n",
    "print(f\"Tokenizer path: {TOKENIZER_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify corpus exists on Drive\n",
    "import os\n",
    "\n",
    "corpus_files = os.listdir(CORPUS_PATH)\n",
    "print(f\"Found {len(corpus_files)} files in corpus:\")\n",
    "for f in sorted(corpus_files)[:10]:\n",
    "    print(f\"  {f}\")\n",
    "if len(corpus_files) > 10:\n",
    "    print(f\"  ... and {len(corpus_files) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone the code repository to Colab's LOCAL storage (not Drive!)\n# Code goes to /content/saslm, Data stays on Drive at /content/drive/MyDrive/saslm\nimport os\n\nCODE_PATH = '/content/saslm'  # Local Colab storage (fast, temporary)\n\nif os.path.exists(CODE_PATH):\n    print('Repo already exists, pulling latest changes...')\n    !cd {CODE_PATH} && git pull\nelse:\n    print('Cloning repository...')\n    !git clone https://github.com/maheshcr/saslm.git {CODE_PATH}\n\n%cd {CODE_PATH}\nprint(f\"\\nWorking directory: {os.getcwd()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch transformers tokenizers datasets wandb tqdm pyyaml numpy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Tokenizer (if not already done)\n",
    "\n",
    "The tokenizer will be saved to Google Drive so you don't need to retrain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if tokenizer exists on Drive\n",
    "import os\n",
    "\n",
    "tokenizer_file = f'{TOKENIZER_PATH}/tokenizer.json'\n",
    "\n",
    "if not os.path.exists(tokenizer_file):\n",
    "    print(\"Training tokenizer (this takes ~5 minutes)...\")\n",
    "    !python src/data/train_tokenizer.py \\\n",
    "        --corpus {CORPUS_PATH} \\\n",
    "        --vocab-size 16384 \\\n",
    "        --output {TOKENIZER_PATH}\n",
    "else:\n",
    "    print(f\"Tokenizer already exists at {TOKENIZER_PATH}\")\n",
    "    !python src/data/train_tokenizer.py --analyze {TOKENIZER_PATH} --corpus {CORPUS_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose experiment\n",
    "EXPERIMENT = \"EXP-A1\"  # Options: EXP-A1, EXP-B1, EXP-A2, EXP-B2\n",
    "\n",
    "config_map = {\n",
    "    \"EXP-A1\": \"configs/exp_a1_prose_only.yaml\",\n",
    "    \"EXP-B1\": \"configs/exp_b1_prose_only_finetune.yaml\",\n",
    "    \"EXP-A2\": \"configs/exp_a2_prose_poetry.yaml\",\n",
    "    \"EXP-B2\": \"configs/exp_b2_prose_poetry_finetune.yaml\",\n",
    "}\n",
    "\n",
    "CONFIG_PATH = config_map[EXPERIMENT]\n",
    "print(f\"Selected: {EXPERIMENT}\")\n",
    "print(f\"Config: {CONFIG_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update config to use Drive paths\n",
    "import yaml\n",
    "\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Update paths to use Google Drive\n",
    "config['data']['corpus_path'] = CORPUS_PATH\n",
    "config['tokenizer']['tokenizer_path'] = TOKENIZER_PATH\n",
    "config['hardware']['drive_path'] = EXPERIMENTS_PATH\n",
    "\n",
    "# Save updated config\n",
    "updated_config_path = f'/content/saslm/configs/{EXPERIMENT.lower()}_updated.yaml'\n",
    "with open(updated_config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"Updated config saved to: {updated_config_path}\")\n",
    "print(f\"\\nKey paths:\")\n",
    "print(f\"  Corpus: {config['data']['corpus_path']}\")\n",
    "print(f\"  Tokenizer: {config['tokenizer']['tokenizer_path']}\")\n",
    "print(f\"  Checkpoints: {config['hardware']['drive_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View updated config\n",
    "!cat {updated_config_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Training\n",
    "\n",
    "Training will:\n",
    "- Auto-resume from checkpoint if disconnected\n",
    "- Save checkpoints to Google Drive every 1000 steps\n",
    "- Log metrics to wandb (optional)\n",
    "- Detect grokking phenomenon\n",
    "\n",
    "**If Colab disconnects**: Just re-run this cell. It will auto-resume!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Login to Weights & Biases for tracking\n",
    "# import wandb\n",
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training (will auto-resume if checkpoint exists)\n",
    "!python src/training/train.py \\\n",
    "    --config {updated_config_path} \\\n",
    "    --resume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model and generate samples\n",
    "import torch\n",
    "from tokenizers import Tokenizer\n",
    "import sys\n",
    "sys.path.insert(0, '/content/saslm')\n",
    "\n",
    "from src.training.train import GPT\n",
    "from src.training.checkpoint_manager import CheckpointManager\n",
    "\n",
    "# Load tokenizer from Drive\n",
    "tokenizer = Tokenizer.from_file(f'{TOKENIZER_PATH}/tokenizer.json')\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "print(f\"Loaded tokenizer with {vocab_size:,} tokens\")\n",
    "\n",
    "# Create model\n",
    "model = GPT(\n",
    "    vocab_size=vocab_size,\n",
    "    block_size=512,\n",
    "    n_layer=6,\n",
    "    n_head=6,\n",
    "    n_embd=384,\n",
    ")\n",
    "\n",
    "# Load best checkpoint from Drive\n",
    "checkpoint_mgr = CheckpointManager(\n",
    "    experiment_name=EXPERIMENT,\n",
    "    base_path=EXPERIMENTS_PATH,\n",
    ")\n",
    "checkpoint_mgr.load_best(model, device='cuda')\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "prompts = [\n",
    "    \"The Supermind is\",\n",
    "    \"The psychic being differs from the soul in that\",\n",
    "    \"The goal of Integral Yoga is not merely liberation but\",\n",
    "    \"In the process of spiritual evolution,\",\n",
    "    \"The three modes of Nature are\",\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    # Encode\n",
    "    encoded = tokenizer.encode(prompt)\n",
    "    input_ids = torch.tensor([encoded.ids], device='cuda')\n",
    "    \n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, max_new_tokens=100, temperature=0.8, top_k=50)\n",
    "    \n",
    "    # Decode\n",
    "    generated = tokenizer.decode(output[0].tolist())\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Generated: {generated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run LLM Judge Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set API key for evaluation (choose one)\n",
    "import os\n",
    "\n",
    "# Option 1: OpenAI\n",
    "# os.environ['OPENAI_API_KEY'] = 'your-key-here'\n",
    "\n",
    "# Option 2: Anthropic\n",
    "# os.environ['ANTHROPIC_API_KEY'] = 'your-key-here'\n",
    "\n",
    "# Option 3: Google\n",
    "# os.environ['GEMINI_API_KEY'] = 'your-key-here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "# !python src/evaluate.py \\\n",
    "#     --model-path {EXPERIMENTS_PATH}/{EXPERIMENT}/checkpoint_best.pt \\\n",
    "#     --tokenizer {TOKENIZER_PATH} \\\n",
    "#     --judge claude \\\n",
    "#     --output {DRIVE_BASE}/results/{EXPERIMENT}_eval.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. View Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load metrics from Drive\n",
    "metrics_path = f'{EXPERIMENTS_PATH}/{EXPERIMENT}/metrics.jsonl'\n",
    "\n",
    "if os.path.exists(metrics_path):\n",
    "    steps = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    with open(metrics_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            steps.append(data['step'])\n",
    "            if 'train_loss' in data:\n",
    "                train_losses.append((data['step'], data['train_loss']))\n",
    "            if 'val_loss' in data:\n",
    "                val_losses.append((data['step'], data['val_loss']))\n",
    "\n",
    "    # Plot\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "    # Training loss\n",
    "    if train_losses:\n",
    "        x, y = zip(*train_losses)\n",
    "        ax1.plot(x, y, label='Train Loss', alpha=0.7)\n",
    "    if val_losses:\n",
    "        x, y = zip(*val_losses)\n",
    "        ax1.plot(x, y, label='Val Loss', alpha=0.7)\n",
    "    ax1.set_xlabel('Step')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Gap (for grokking detection)\n",
    "    if train_losses and val_losses:\n",
    "        train_dict = dict(train_losses)\n",
    "        val_dict = dict(val_losses)\n",
    "        common_steps = sorted(set(train_dict.keys()) & set(val_dict.keys()))\n",
    "        if common_steps:\n",
    "            gaps = [val_dict[s] - train_dict[s] for s in common_steps]\n",
    "            ax2.plot(common_steps, gaps, label='Val - Train Gap', color='purple')\n",
    "            ax2.axhline(y=0, color='gray', linestyle='--')\n",
    "            ax2.set_xlabel('Step')\n",
    "            ax2.set_ylabel('Gap')\n",
    "            ax2.set_title('Generalization Gap (Grokking Indicator)')\n",
    "            ax2.legend()\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{DRIVE_BASE}/results/{EXPERIMENT}_training_curves.png', dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"No metrics file found at {metrics_path}\")\n",
    "    print(\"Run training first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Upload to HuggingFace (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to HuggingFace\n",
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model\n",
    "# from huggingface_hub import HfApi\n",
    "# api = HfApi()\n",
    "# \n",
    "# api.upload_folder(\n",
    "#     folder_path=f'{EXPERIMENTS_PATH}/{EXPERIMENT}',\n",
    "#     repo_id='your-username/saslm-v2',\n",
    "#     repo_type='model',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "### If Colab Disconnects\n",
    "Just re-run from the \"Run Training\" cell. The training will automatically resume from the last checkpoint saved to Google Drive.\n",
    "\n",
    "### File Locations on Google Drive\n",
    "```\n",
    "/content/drive/MyDrive/saslm/\n",
    "├── clean_prose/              # Your uploaded corpus (23 files)\n",
    "├── tokenizers/\n",
    "│   └── tokenizer_16k/        # Trained tokenizer\n",
    "├── experiments/\n",
    "│   └── EXP-A1/               # Checkpoints & metrics\n",
    "│       ├── checkpoint_latest.pt\n",
    "│       ├── checkpoint_best.pt\n",
    "│       └── metrics.jsonl\n",
    "└── results/                  # Evaluation results\n",
    "```\n",
    "\n",
    "### Expected Training Time\n",
    "- EXP-A1 (from scratch): ~8-12 hours for 100K steps on T4\n",
    "- EXP-B1 (fine-tune): ~4-6 hours for 50K steps on T4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_version": "3.10"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}